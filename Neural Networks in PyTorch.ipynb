{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'grp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-3910039e5eca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mhelper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\helper\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mhelper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munix\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplatform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[0m__version__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'2.5.0'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\helper\\unix.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0matexit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgrp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'grp'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import helper\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5,),(0.5,)),\n",
    "                               ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e40aff78b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap = 'Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "\n",
    "def multi_layer_NW(inputUnits, hiddenUnits, outputUnits):\n",
    "    torch.manual_seed(7)\n",
    "    \n",
    "    n_input = inputUnits\n",
    "    n_hidden = hiddenUnits\n",
    "    n_output = outputUnits\n",
    "    \n",
    "    # weights\n",
    "    w1 = torch.randn(n_input, n_hidden)\n",
    "    w2 = torch.randn(n_hidden, n_output)\n",
    "    \n",
    "    #bias\n",
    "    b1 = torch.randn(1,n_hidden)\n",
    "    b2 = torch.randn(1,n_output)\n",
    "    \n",
    "    return w1,w2,b1,b2\n",
    "\n",
    "def calc_output(features,w1,w2,b1,b2):\n",
    "    h = activation(torch.matmul(features, w1).add_(b1))\n",
    "    output = activation(torch.matmul(h,w2).add_(b2))\n",
    "    return(output)\n",
    "\n",
    "features = torch.flatten(images,start_dim=1)\n",
    "w1,w2,b1,b2 = multi_layer_NW(features.shape[1],256,10)\n",
    "\n",
    "out = calc_output(features,w1,w2,b1,b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([0.1838, 0.1829, 0.1363, 0.1288, 0.1615, 0.1580, 0.1493, 0.1358, 0.1844,\n",
      "        0.1548, 0.1713, 0.1608, 0.1501, 0.1740, 0.1673, 0.1442, 0.1533, 0.1549,\n",
      "        0.1441, 0.1541, 0.1548, 0.1407, 0.1793, 0.1393, 0.1721, 0.1445, 0.1579,\n",
      "        0.1733, 0.1581, 0.1491, 0.1441, 0.1475, 0.1502, 0.1431, 0.1632, 0.1474,\n",
      "        0.1280, 0.1583, 0.1596, 0.1454, 0.2029, 0.1443, 0.1454, 0.1488, 0.1742,\n",
      "        0.1515, 0.1384, 0.1523, 0.1460, 0.1616, 0.1647, 0.1696, 0.1509, 0.1552,\n",
      "        0.1611, 0.1651, 0.1546, 0.1556, 0.1494, 0.1615, 0.1839, 0.1661, 0.1450,\n",
      "        0.1461])\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    num = torch.exp(x)\n",
    "    den = torch.sum(torch.exp(x), dim = 0)\n",
    "    return num/den\n",
    "\n",
    "probabilities = softmax(out)\n",
    "\n",
    "\n",
    "print(probabilities.shape)\n",
    "print(probabilities.sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Relu(x):\n",
    "    if x < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.ReLU):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "        # Define sigmoid activation and softmax output \n",
    "        self.Relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input tensor through each of our operations\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.Relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (Relu): ReLU()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class Network(nn.ReLU):\n",
    "    def __init__():\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(784,128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.Relu(self.fc1(x))\n",
    "        x = F.Relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0285, -0.0028,  0.0297,  ..., -0.0323,  0.0167, -0.0010],\n",
      "        [-0.0196, -0.0263,  0.0145,  ...,  0.0261,  0.0014,  0.0096],\n",
      "        [ 0.0144,  0.0291, -0.0027,  ..., -0.0251,  0.0026, -0.0147],\n",
      "        ...,\n",
      "        [-0.0263,  0.0151, -0.0285,  ...,  0.0191,  0.0010,  0.0089],\n",
      "        [-0.0297,  0.0248, -0.0184,  ..., -0.0235,  0.0150,  0.0055],\n",
      "        [ 0.0321,  0.0311, -0.0267,  ...,  0.0292,  0.0259, -0.0036]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0207, -0.0032, -0.0208, -0.0078, -0.0290, -0.0233,  0.0337, -0.0214,\n",
      "         0.0321, -0.0335, -0.0017, -0.0083,  0.0071,  0.0112, -0.0254,  0.0162,\n",
      "        -0.0291, -0.0189,  0.0181, -0.0013,  0.0179, -0.0161,  0.0319, -0.0280,\n",
      "        -0.0100,  0.0176,  0.0027, -0.0107, -0.0091, -0.0248, -0.0355, -0.0098,\n",
      "        -0.0303, -0.0040, -0.0034, -0.0304,  0.0351,  0.0229, -0.0321,  0.0096,\n",
      "         0.0107, -0.0265,  0.0243,  0.0062, -0.0144, -0.0063,  0.0272,  0.0248,\n",
      "         0.0156, -0.0229,  0.0342,  0.0259, -0.0094, -0.0025,  0.0135, -0.0101,\n",
      "         0.0101,  0.0234,  0.0238,  0.0189,  0.0068,  0.0197,  0.0078,  0.0026,\n",
      "        -0.0256, -0.0058,  0.0234,  0.0265,  0.0113,  0.0176, -0.0157,  0.0012,\n",
      "        -0.0143, -0.0020, -0.0300,  0.0241, -0.0306, -0.0057,  0.0033,  0.0353,\n",
      "        -0.0084, -0.0164,  0.0121, -0.0184,  0.0161, -0.0183, -0.0293,  0.0160,\n",
      "         0.0206,  0.0088, -0.0110, -0.0173,  0.0344,  0.0294,  0.0344,  0.0251,\n",
      "         0.0174, -0.0179,  0.0062,  0.0189, -0.0274,  0.0282,  0.0106, -0.0273,\n",
      "        -0.0347,  0.0092, -0.0095, -0.0029, -0.0258, -0.0281, -0.0077, -0.0354,\n",
      "        -0.0182,  0.0151, -0.0103, -0.0059,  0.0183, -0.0012,  0.0326,  0.0330,\n",
      "        -0.0117,  0.0131,  0.0301, -0.0334,  0.0171,  0.0086,  0.0036,  0.0324],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.fc1.weight)\n",
    "print(model.fc1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set biases to all zeros\n",
    "model.fc1.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0116,  0.0019, -0.0023,  ...,  0.0147,  0.0072,  0.0055],\n",
       "        [ 0.0043, -0.0018, -0.0089,  ...,  0.0001, -0.0050,  0.0118],\n",
       "        [-0.0012,  0.0118, -0.0002,  ..., -0.0142, -0.0006,  0.0046],\n",
       "        ...,\n",
       "        [-0.0156, -0.0005, -0.0017,  ...,  0.0006,  0.0088,  0.0078],\n",
       "        [ 0.0052, -0.0022,  0.0095,  ..., -0.0046, -0.0087, -0.0053],\n",
       "        [ 0.0008,  0.0146, -0.0227,  ...,  0.0134,  0.0013, -0.0045]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample from random normal with standard dev = 0.01\n",
    "model.fc1.weight.data.normal_(std=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab some data \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
    "images.resize_(64, 1, 784)\n",
    "# or images.resize_(images.shape[0], 1, 784) to automatically get batch size\n",
    "\n",
    "# Forward pass through the network\n",
    "img_idx = 0\n",
    "ps = model.forward(images[img_idx,:])\n",
    "\n",
    "img = images[img_idx]\n",
    "#helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (5): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model)\n",
    "\n",
    "# Forward pass through the network and display output\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "ps = model.forward(images[0,:])\n",
    "#helper.view_classify(images[0].view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=128, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0298,  0.0304, -0.0296,  ..., -0.0272,  0.0090, -0.0264],\n",
       "        [-0.0154,  0.0288, -0.0014,  ...,  0.0160, -0.0195,  0.0278],\n",
       "        [ 0.0066, -0.0283, -0.0170,  ...,  0.0011, -0.0098,  0.0352],\n",
       "        ...,\n",
       "        [-0.0080, -0.0352, -0.0181,  ...,  0.0279, -0.0076,  0.0036],\n",
       "        [ 0.0137,  0.0285,  0.0202,  ...,  0.0149,  0.0033, -0.0273],\n",
       "        [-0.0155, -0.0011, -0.0348,  ...,  0.0157,  0.0056,  0.0097]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model[0])\n",
    "model[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "model = nn.Sequential(OrderedDict([\n",
    "                      ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "                      ('relu1', nn.ReLU()),\n",
    "                      ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "                      ('relu2', nn.ReLU()),\n",
    "                      ('output', nn.Linear(hidden_sizes[1], output_size)),\n",
    "                      ('softmax', nn.Softmax(dim=1))]))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=128, bias=True)\n",
      "Linear(in_features=784, out_features=128, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(model[0])\n",
    "print(model.fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
