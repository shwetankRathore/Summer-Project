{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2945, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim = 1))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Get our data\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[-0.0021, -0.0021, -0.0021,  ..., -0.0021, -0.0021, -0.0021],\n",
      "        [ 0.0010,  0.0010,  0.0010,  ...,  0.0010,  0.0010,  0.0010],\n",
      "        [-0.0012, -0.0012, -0.0012,  ..., -0.0012, -0.0012, -0.0012],\n",
      "        ...,\n",
      "        [ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002],\n",
      "        [-0.0030, -0.0030, -0.0030,  ..., -0.0030, -0.0030, -0.0030],\n",
      "        [ 0.0044,  0.0044,  0.0044,  ...,  0.0044,  0.0044,  0.0044]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[ 0.0349,  0.0186,  0.0210,  ..., -0.0120, -0.0199, -0.0148],\n",
      "        [-0.0122,  0.0209,  0.0208,  ..., -0.0012, -0.0337,  0.0342],\n",
      "        [-0.0071,  0.0265,  0.0278,  ..., -0.0347, -0.0243, -0.0220],\n",
      "        ...,\n",
      "        [-0.0026,  0.0261,  0.0053,  ..., -0.0312, -0.0343, -0.0061],\n",
      "        [ 0.0053, -0.0330,  0.0007,  ...,  0.0029,  0.0063, -0.0027],\n",
      "        [ 0.0012,  0.0151,  0.0148,  ..., -0.0225,  0.0046, -0.0308]],\n",
      "       requires_grad=True)\n",
      "Gradient - tensor([[-0.0023, -0.0023, -0.0023,  ..., -0.0023, -0.0023, -0.0023],\n",
      "        [ 0.0018,  0.0018,  0.0018,  ...,  0.0018,  0.0018,  0.0018],\n",
      "        [-0.0054, -0.0054, -0.0054,  ..., -0.0054, -0.0054, -0.0054],\n",
      "        ...,\n",
      "        [ 0.0012,  0.0012,  0.0012,  ...,  0.0012,  0.0012,  0.0012],\n",
      "        [ 0.0007,  0.0007,  0.0007,  ...,  0.0007,  0.0007,  0.0007],\n",
      "        [ 0.0062,  0.0062,  0.0062,  ...,  0.0062,  0.0062,  0.0062]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model[0].weight)\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# Clear the gradients, do this because gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass, then backward pass, then update weights\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient -', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights -  Parameter containing:\n",
      "tensor([[ 0.0349,  0.0187,  0.0210,  ..., -0.0120, -0.0199, -0.0148],\n",
      "        [-0.0122,  0.0209,  0.0208,  ..., -0.0013, -0.0337,  0.0342],\n",
      "        [-0.0071,  0.0265,  0.0279,  ..., -0.0347, -0.0243, -0.0219],\n",
      "        ...,\n",
      "        [-0.0026,  0.0261,  0.0052,  ..., -0.0312, -0.0344, -0.0061],\n",
      "        [ 0.0053, -0.0330,  0.0006,  ...,  0.0029,  0.0063, -0.0027],\n",
      "        [ 0.0012,  0.0150,  0.0147,  ..., -0.0226,  0.0046, -0.0309]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Take an update step and view the new weights\n",
    "optimizer.step()\n",
    "print('Updated weights - ', model[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9662835031175918\n",
      "Training loss: 0.930400448821501\n",
      "Training loss: 0.5507885436259353\n",
      "Training loss: 0.44034753337915516\n",
      "Training loss: 0.39039392883716617\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # TODO: Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #print('Gradient -', model[0].weight.grad)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
